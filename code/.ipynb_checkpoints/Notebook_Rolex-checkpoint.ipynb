{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Betting strategies \n",
    "## _England Premiere League Results & Odds Dataset_\n",
    "\n",
    "### I. Introduction\n",
    "\n",
    "> You do not know anything about sports betting or you want to implement a new strategy? This notebook will help you understand this world, and also provide you a **betting strategy** that you will be able to apply on your own.\n",
    "\n",
    "In this report, we will take the example of Football, one of the sports with the highest number of bets. More precisely, we will concentrate on **England Premiere League results**, because its great number of matches will allow us to test and build a strategy. \n",
    "\n",
    "##### Explanations on betting's vocabulary\n",
    "First, let's set up the vocabulary. While betting,  _odds_ are linked to each bet you make. Betting odds tell you how likely an event is to happen, and represents how much money you could win if your bet realizes itself.\n",
    "> For example, you are on a betting website. If the odd is set as 1.40 for \"Home team win\" and you put 10€ on this odd, if the Home team actually wins (so your prediction realizes itself), you will earn 4€ and get back your first 10€.\n",
    "\n",
    "There is the possibility to bet on different type of results before a match. Here, we will take into account these type of bets: the number of goals during a game(< 2.5 goals or > 2.5 goals), the other on the match result (Home team wins, Away team wins, Draw match).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Dataset & Variables\n",
    "\n",
    "The dataset we chose groups the results of the English Premier League matches **from 2008 to 2019**. The variables available are about the matches : the match's **ID**, the match's **date time**, the **Home team**, the **Away team**, the final **number of goals**, the **match result** (Home Team win, Away Team win or Draw Match), the **team's ranking** of the previous Football season (static rank at the end of the past season), the **referee** for the match, the number of **shots**, the number of **fouls**, and the other variables are not directly linked to the match statistics. These other variables are **the odds set before the match** by **different betting websites**. Some of these odds are set on the **number of goals** (< or > than 2.5 goals at the end of the match for the Home or Away Team), while others are set on the **final result** of the match (Home Team win, Away Team win, Draw Match).\n",
    "\n",
    "### III. Goal of the project & models\n",
    "\n",
    "The goal of the project is to build a model that can predict the following output : Home Team win, Away Team win or Draw match.\n",
    "Of course, the model will not predict perfectly the output, but by knowing which match result have the most chances to happen can create some winning bets. This will be done through **Classifications** models\n",
    "\n",
    "We decided to build two models : \n",
    "- One time, we will try to predict a match result based on the **betting websites' predictions**, that can be seen **through the odds** websites put on the possible result. \n",
    "- Another time we will use the **Match Statistics**, with the rank of each team, the number of shots/fouls, the number of goals, etc. \n",
    "\n",
    "In order to obtain these predictions, we will also try two kind of classifications : **Descision Trees** and **Logistic Regressions**. \n",
    "\n",
    "> In the end, we will evaluate the relevance of each classification method, and also define **which independant variables** (Odds or Statitics of the Match) **explained the best the Match Result**.\n",
    "\n",
    "### IV. Methodology\n",
    "\n",
    "1. At first, we will import the packages that we will need during this analyse.\n",
    "2. Then, we will upload, clean and add the necessary variables to complete the Dataset.\n",
    "3. Some variables will be transformed the variables in a way we can use them properly.  \n",
    "4. Consequently, we will create the models for each problem, with the two classification methods.\n",
    "5. We will also evaluate the accuracy of the models and adapt them to reduce the noise.\n",
    "6. To add, we will integrate some graphics to help a better understanding of the project.\n",
    "7. Finally, we will draw some conclusions that we can be retrieved from these classfications and methodologies.\n",
    "\n",
    "> A final retrospective on this project will also be done.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(Unfortunately we did find one with all the variables we were looking for, like the Ex-Rank variable which represent the ranking of the teams for the last season. Our Data contained also a few of missing value so we had to deal with it.) ?\n",
    "\n",
    "As we face a classification problem with a binary output which is \"Win or not Win\", we will construct two models with Logistic Regressions, one model with the match's statistics, another with odds as inputs and compare them. We will also use a decision tree with the same inputs and output. Finally, we will compare the two methodologies. \n",
    "\n",
    "Finally we will analyse our models and try to tink about how we could improve them and how they could be useful for business.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import collections  as mc\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the dataset, in a csv file, that we decided to call _data_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 826,
     "status": "ok",
     "timestamp": 1574259812216,
     "user": {
      "displayName": "Abdoo Aloraib",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUO9oHDV-z7IuSjn4Tf1zgFORfDmiFylWCNgAY=s64",
      "userId": "10713939061096290051"
     },
     "user_tz": -60
    },
    "id": "imYCkCGmMNIw",
    "outputId": "a9c39db3-798c-4d3d-d073-a62a7c8b71d4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We use the Dataset with the games of the season 2018\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/abdul232/DMML_Team_Rolex/master/data/England_2008_2018_Premiere_League_Final.csv',sep=\";\")\n",
    "\n",
    "#data = data.sort_values(by=\"Match_ID\",ascending=True)\n",
    "# view the first 10 rows \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have some NaN variables in our data due to a format change, so we have to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.drop([\"Unnamed: 49\", \"Unnamed: 50\", \"Unnamed: 51\",\"Unnamed: 52\",\"Unnamed: 53\",\"Unnamed: 54\",\"Unnamed: 55\",\"Unnamed: 56\",\"Unnamed: 57\",\"Unnamed: 58\",\"Unnamed: 59\",\"Unnamed: 60\",\"Unnamed: 61\",\"Unnamed: 62\",\"Unnamed: 63\",\"Unnamed: 64\",\"Unnamed: 65\",\"Unnamed: 66\",\"Unnamed: 67\",\"Unnamed: 68\",\"Unnamed: 69\"], axis=1)\n",
    "\n",
    "#We have a new dimension\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset without the _NaN counts_ **4'176** rows for **49** columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we setted up the **types of the variables**. We will change some as int (integer), the date as datetime, while other will remain objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We have to change the type of some variable\n",
    "data['Match_ID'] = data.Match_ID.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We have to change the type of some variable\n",
    "data['Date'] = pd.to_datetime(data['Date'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We have to change the type of some variable\n",
    "data[['Home Team Goals', 'Away Team Goals', 'Home Team Shots','Away Team Shots', 'Home Team Shots on Target', 'Away Team Shots on Target', 'Home Fouls Committed', 'Away Fouls Committed', 'Home Corners', 'Away Corners', 'Home Yellow Cards', 'Away Yellow Cards', 'Home Red Cards', 'Away Red Cards']]= data[['Home Team Goals', 'Away Team Goals', 'Home Team Shots','Away Team Shots', 'Home Team Shots on Target', 'Away Team Shots on Target', 'Home Fouls Committed', 'Away Fouls Committed', 'Home Corners', 'Away Corners', 'Home Yellow Cards', 'Away Yellow Cards', 'Home Red Cards', 'Away Red Cards']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressions\n",
    "\n",
    "To build a betting strategy, it is first relevant to know how frequently the betting companies makes right predicting or not. So, in order to undertand this fact, we will build three different scatter plot :\n",
    "> * when the official result is the victory of the home team crossed with the \"Home team win\" odd.\n",
    "> * When the official result is the victory of the away team crossed with the match result with the \"Away team win\" odd.\n",
    "> * When the official result is draw crossed with the \"Draw\"odd.\n",
    "\n",
    "Each graph will show the odds of all the betting websites, to compare them.\n",
    "\n",
    "A match has 3 different possible results (the Home Team wins, a Draw, the Away Team wins) and we need a binary variables for each of them to do 3 different regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We wo, one for the Home team wins, one for the draws and one for the Away team wins\n",
    "data = pd.get_dummies(data, columns=['Match Result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalistion\n",
    "\n",
    "We will normalize the odds to have a better comparison thanks to a common scale for all variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# separate the data from the target attributes\n",
    "#X = data['B365 Home','B365 Draw','B365 Away','Bet&Win Home','Bet&Win Draw','Bet&Win Away','Interwetten Home','Iterwetten Draw','Interwetten Away','William Hill Home','William Hill Draw','William Hill Away','VC Bet Home','VC Bet Draw','VC Bet Away']\n",
    "# normalisation par formule (x - x.min()) / (x.max() - x.min())\n",
    "cols_to_norm = ['B365 Home','B365 Draw','B365 Away','Bet&Win Home','Bet&Win Draw','Bet&Win Away','Interwetten Home','Interwetten Draw','Interwetten Away','William Hill Home','William Hill Draw','William Hill Away','VC Bet Home','VC Bet Draw','VC Bet Away']\n",
    "data[cols_to_norm] = data[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min())) \n",
    "data[cols_to_norm].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global view of the results in comparison to the odds\n",
    "\n",
    ">We will build scatter plots for each of the 3 differents possible results we have in a match a compare them with the odds.\n",
    "\n",
    "\n",
    "We will first do it with the **Home team wins scenario**, if the Home team wins the output is 1  otherwise it's 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "#tips = sns.load_dataset(data)\n",
    "\n",
    "a_B365_Home = sns.scatterplot(x=\"B365 Home\", y=\"Match Result_H\", data=data)\n",
    "\n",
    "a_BetWin_Home = sns.scatterplot(x=\"Bet&Win Home\", y=\"Match Result_H\", data=data)\n",
    "\n",
    "a_Interwetten_Home = sns.scatterplot(x=\"Interwetten Home\", y=\"Match Result_H\", data=data)\n",
    "\n",
    "a_WilliamHill_Home = sns.scatterplot(x=\"William Hill Home\", y=\"Match Result_H\", data=data)\n",
    "\n",
    "a_VCBet_Home = sns.scatterplot(x=\"VC Bet Home\", y=\"Match Result_H\", data=data)\n",
    "\n",
    "a_VCBet_Home.set(xlabel='Website Odd while Home Team wins', ylabel='Home team won [1]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** As we can see higher the odd is, the less a team has chance to win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_B365_Draw = sns.scatterplot(x=\"B365 Draw\", y=\"Match Result_D\", data=data)\n",
    "\n",
    "a_BetWin_Draw = sns.scatterplot(x=\"Bet&Win Draw\", y=\"Match Result_D\", data=data)\n",
    "\n",
    "a_Interwetten_Draw = sns.scatterplot(x=\"Interwetten Draw\", y=\"Match Result_D\", data=data)\n",
    "\n",
    "a_WilliamHill_Draw = sns.scatterplot(x=\"William Hill Draw\", y=\"Match Result_D\", data=data)\n",
    "\n",
    "a_VCBet_Draw = sns.scatterplot(x=\"VC Bet Draw\", y=\"Match Result_D\", data=data)\n",
    "\n",
    "a_VCBet_Draw.set(xlabel='Website Odd while Draw match', ylabel='Draw [1]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** We can observe the same trend as the previous point, but it's important to know that there is a limit for the draws odds, they can not be too high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_B365_Away = sns.scatterplot(x=\"B365 Away\", y=\"Match Result_A\", data=data)\n",
    "\n",
    "a_BetWin_Away = sns.scatterplot(x=\"Bet&Win Away\", y=\"Match Result_A\", data=data)\n",
    "\n",
    "a_Interwetten_Away = sns.scatterplot(x=\"Interwetten Away\", y=\"Match Result_A\", data=data)\n",
    "\n",
    "a_WilliamHill_Away = sns.scatterplot(x=\"William Hill Away\", y=\"Match Result_A\", data=data)\n",
    "\n",
    "a_VCBet_Away = sns.scatterplot(x=\"VC Bet Away\", y=\"Match Result_H\", data=data)\n",
    "\n",
    "a_VCBet_Away.set(xlabel='Website Odd while Away Team wins', ylabel='Away team won [1]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** We can observe the same trend as the previous points, but it seems to have more surprising results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between two models\n",
    "\n",
    "We will compare two model:\n",
    "\n",
    "> - Logistic Regressions comparing the Odd prediction to the statistics of the match prediction\n",
    "> - Decision Trees comparing the Odd prediction to the statistics of the match prediction\n",
    "## Logistic Regression - Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here is the 1st logistic regression for Home Team Win:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['B365 Home','Bet&Win Home','Interwetten Home','William Hill Home','VC Bet Home']\n",
    "\n",
    "X = np.array(data[feature_names])\n",
    "y = np.array(data[\"Match Result_H\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression with 5 fold cross validation\n",
    "LR = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best regulariser parameter\n",
    "LR.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "LR.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, LR.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confusion matrix, (code from the Lab 5.0)\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "y_pred = LR.predict(X_train)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Reds):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.ylim([-0.5, 2.5])\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout();\n",
    "    \n",
    "    ax.xaxis.set_ticklabels([\"No Home Win\", \"Home Win\"])\n",
    "    ax.yaxis.set_ticklabels([\"No Home Win\", \"Home Win\"])\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_train, y_pred, classes = y[unique_labels(y_train, y_pred)],title='Confusion matrix, with normalization')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
    "\n",
    "Precision = precision_score(y_train, y_pred, pos_label='Yes')\n",
    "\n",
    "print(Precision)\n",
    "\n",
    "\n",
    "Recall = recall_score(y_train, y_pred, pos_label='Yes')\n",
    "\n",
    "print(Recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here is the 2nd logistic regression for Draws:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['B365 Draw','Bet&Win Draw','Interwetten Draw','William Hill Draw','VC Bet Draw']\n",
    "\n",
    "X = np.array(data[feature_names])\n",
    "y = np.array(data[\"Match Result_D\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression with 5 fold cross validation\n",
    "LR = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best regulariser parameter\n",
    "LR.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "LR.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, LR.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confusion matrix, (code from the Lab 5.0)\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "y_pred = LR.predict(X_train)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Greens):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, with normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.ylim([-0.5, 2.5])\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout();\n",
    "    \n",
    "    ax.xaxis.set_ticklabels([\"No Draw\", \"Draw\"])\n",
    "    ax.yaxis.set_ticklabels([\"No Draw\", \"Draw\"])\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_train, y_pred, classes = y[unique_labels(y_train, y_pred)],title='Confusion matrix, with normalization')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here is the 3rd logistic regression for Away wins:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['B365 Away','Bet&Win Away','Interwetten Away','William Hill Away','VC Bet Away']\n",
    "\n",
    "X = np.array(data[feature_names])\n",
    "y = np.array(data[\"Match Result_A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression with 5 fold cross validation\n",
    "LR = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best regulariser parameter\n",
    "LR.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "LR.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, LR.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confusion matrix, (code from the Lab 5.0)\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "y_pred = LR.predict(X_train)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, with normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.ylim([-0.5, 2.5])\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout();\n",
    "    \n",
    "    ax.xaxis.set_ticklabels([\"No Away win\", \"Away win\"])\n",
    "    ax.yaxis.set_ticklabels([\"No Away win\", \"Away win\"])\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_train, y_pred, classes = y[unique_labels(y_train, y_pred)],title='Confusion matrix, with normalization')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Logistic Regression - Statistics\n",
    "**Logistic Regression for Home winwith statistics**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"Home ex-Rank\",\"Home Team Shots\",\"Away ex-Rank\", \"Away Team Shots\",\"Home Team Shots on Target\", \"Away Team Shots on Target\", \"Home Fouls Committed\", \"Away Fouls Committed\", \"Home Corners\", \"Away Corners\", \"Home Yellow Cards\", \"Away Yellow Cards\", \"Home Red Cards\", \"Away Red Cards\"]\n",
    "#feature_names = ['B365 Home']\n",
    "X = np.array(data[feature_names])\n",
    "y = np.array(data[\"Match Result_H\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression with 5 fold cross validation\n",
    "LR_MS = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_MS.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best regulariser parameter\n",
    "LR_MS.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "LR_MS.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "LR_MS.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression for Draws with statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"Home ex-Rank\",\"Home Team Shots\",\"Away ex-Rank\", \"Away Team Shots\",\"Home Team Shots on Target\", \"Away Team Shots on Target\", \"Home Fouls Committed\", \"Away Fouls Committed\", \"Home Corners\", \"Away Corners\", \"Home Yellow Cards\", \"Away Yellow Cards\"]\n",
    "#feature_names = ['B365 Home']\n",
    "X = np.array(data[feature_names])\n",
    "y = np.array(data[\"Match Result_D\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression with 5 fold cross validation\n",
    "LR_MSD = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_MSD.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best regulariser parameter\n",
    "LR_MSD.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "LR_MS.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "LR_MS.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression for Away win with statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"Home ex-rank\",\"Home Team Shots\",\"Away ex-rank\", \"Away Team Shots\",\"Home Team Shots on Target\", \"Away Team Shots on Target\", \"Home Fouls Committed\", \"Away Fouls Committed\", \"Home Corners\", \"Away Cornners\", \"Home Yellow Cards\", \"Away Yellow Cards\", \"Home Red Cards\", \"Away Red Cards\"]\n",
    "#feature_names = ['B365 Home']\n",
    "X = np.array(data[feature_names])\n",
    "y = np.array(data[\"Match Result_A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression with 5 fold cross validation\n",
    "LR_MS = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_MS.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best regulariser parameter\n",
    "LR_MS.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "LR_MS.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "LR_MS.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees - Odds\n",
    "\n",
    "**Decision Tree for Home win**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['B365 Home','Bet&Win Home','Interwetten Home','William Hill Home','VC Bet Home']\n",
    "\n",
    "X = data[feature_names]\n",
    "y = data[\"Match Result_H\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth of the decision tree\n",
    "clf.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees - Match Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Home ex-Rank', 'Home Team Shots', 'Away ex-Rank', 'Away Team Shots', 'Home Team Shots on Target', 'Away Team Shots on Target', 'Home Fouls Committed', 'Away Fouls Committed', 'Home Corners', 'Away Corners', 'Home Yellow Cards', 'Away Yellow Cards', 'Home Red Cards', 'Away Red Cards']\n",
    "\n",
    "X = np.array(data[feature_names])\n",
    "y = np.array(data[\"Match Result_H\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth of the decision tree\n",
    "clf.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
