{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Betting strategies \n",
    "# _England Premiere League Match Results & Odds Dataset_\n",
    "\n",
    "## I. Introduction\n",
    "\n",
    "> You do not know anything about sports betting or you want to implement a new strategy? This notebook will help you understand this world, and also provide you a **betting strategy** that you will be able to apply on your own.\n",
    "\n",
    "In this report, we will take the example of Football, one of the sports with the highest number of bets. More precisely, we will concentrate on **England Premiere League match results**, because its great number of matches will allow us to test and build a strategy.\n",
    "\n",
    "### Explanations on betting's vocabulary\n",
    "First, let's set up the vocabulary. While betting,  _odds_ are linked to each bet you make. Betting odds tell you how likely an event is to happen, and represents how much money you could win if your bet realizes itself.\n",
    "\n",
    "> For example, you are on a betting website. If the odd is set as 1.40 for \"Home team win\" and you put 10€ on this odd, if the Home team actually wins (so your prediction realizes itself), you will earn 4€ and get back your first 10€.\n",
    "\n",
    "There is the possibility to bet on different type of results before a match. Here, we will take into account the bets on the match result (Home team wins, Away team wins, Draw match).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Dataset & Variables\n",
    "\n",
    "The dataset we chose groups the results of the English Premier League matches **from 2008 to 2019**. It was taken from the following website:\n",
    "We also added some features to this dataset, taken from this website:\n",
    "\n",
    "The variables available are about the matches: the match's **ID**, the match's **date time**, the **Home team**, the **Away team**, the final **number of goals**, the **match result** (Home Team win, Away Team win or Draw Match), the **team's ranking** of the previous Football season (static rank at the end of the past season), the **referee** for the match, the number of **shots**, the number of **fouls**, and the other variables are not directly linked to the match statistics. These other variables are **the odds set before the match** by **different betting websites**. These odds are set on the **final result** of a match (Home Team win, Away Team win, Draw Match).\n",
    "\n",
    "## III. Goal of the project & models\n",
    "\n",
    "The goal of the project is to build a model that can predict the following output : Home Team win, Away Team win or Draw match.\n",
    "Of course, the model will not predict perfectly the output, but by knowing which match result have the most chances to happen can create some winning bets. This will be done through **Classifications** models.\n",
    "\n",
    "We decided to build two models, taking into acount different independant variables: \n",
    "- One time, we will try to predict a match result based on the **betting websites' predictions**, that can be seen **through the odds** websites put on the possible result. \n",
    "\n",
    "- Another time we will use the **Match Statistics**, with the rank of each team, the number of shots/fouls, the number of goals, etc. \n",
    "\n",
    "In order to obtain these predictions, we will also try two classifications models: **Descision Trees** and **Logistic Regressions**. \n",
    "\n",
    "> In the end, we will evaluate the relevance of each classification model, and also define **which independant variables** (Odds or Statitics of the Match) **explained the best the Match Result**.\n",
    "\n",
    "## IV. Methodology\n",
    "\n",
    "1. At first, we will import the packages that we will need during this analyse.\n",
    "2. Then, we will upload, clean and add the necessary variables to complete the Dataset.\n",
    "3. Some variables will be transformed the variables in a way we can use them properly.\n",
    "4. Following this point, we will create scatter plots to show the repartition between the realized prediction vs non realized prediction. (When the match Odd is set on Home win => 0 the match result is Home did not win, 1 when Home won) \n",
    "5. Consequently, we will create the classification models (Logistic regression, then decision trees). It will be done for each match result, using one time the match statistics, the other time using the odds. \n",
    "6. We will also evaluate the accuracy of the models and create confusion matrixes to have a visual representation of the project.\n",
    "7. Finally, we will draw some conclusions that we can be retrieved from these classfications and methodologies.\n",
    "\n",
    "> We will also analyse our models and try to tink about how we could improve them and how they could be useful for business.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import collections  as mc\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The dataset\n",
    "\n",
    "The following table shows the 10 first rows of the dataset. It was uploaded from a csv file, and we decided yo name it **_data_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 826,
     "status": "ok",
     "timestamp": 1574259812216,
     "user": {
      "displayName": "Abdoo Aloraib",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCUO9oHDV-z7IuSjn4Tf1zgFORfDmiFylWCNgAY=s64",
      "userId": "10713939061096290051"
     },
     "user_tz": -60
    },
    "id": "imYCkCGmMNIw",
    "outputId": "a9c39db3-798c-4d3d-d073-a62a7c8b71d4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We use the Dataset with the games of the season 2008 to 2018\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/abdul232/DMML_Team_Rolex/master/data/England_2008_2018_Premiere_League_Final.csv',sep=\";\")\n",
    "\n",
    "# view of the first rows \n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have some _NaN_ variables in our data due to a format change, so we have to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.drop([\"Unnamed: 49\", \"Unnamed: 50\", \"Unnamed: 51\",\"Unnamed: 52\",\"Unnamed: 53\",\"Unnamed: 54\",\"Unnamed: 55\",\"Unnamed: 56\",\"Unnamed: 57\",\"Unnamed: 58\",\"Unnamed: 59\",\"Unnamed: 60\",\"Unnamed: 61\",\"Unnamed: 62\",\"Unnamed: 63\",\"Unnamed: 64\",\"Unnamed: 65\",\"Unnamed: 66\",\"Unnamed: 67\",\"Unnamed: 68\",\"Unnamed: 69\"], axis=1)\n",
    "\n",
    "#We have a new dimension\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ce n'est plus le cas !\n",
    "We have also seen that some rows were showing _NaN_ data, so we removed them too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this dataset (without the _NaN_ ) counts **4'176** rows for **49** columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Changing variables types\n",
    "\n",
    "Now, as we settled up the **types of the variables**. We will change some as int (integer), the date as datetime, while other will remain objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We have to change the type of some variable (integer)\n",
    "data['Match_ID'] = data.Match_ID.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We have to change the type of some variable (integer)\n",
    "data[['Home Team Goals', 'Away Team Goals', 'Home Team Shots','Away Team Shots', 'Home Team Shots on Target', 'Away Team Shots on Target', 'Home Fouls Committed', 'Away Fouls Committed', 'Home Corners', 'Away Corners', 'Home Yellow Cards', 'Away Yellow Cards', 'Home Red Cards', 'Away Red Cards']]= data[['Home Team Goals', 'Away Team Goals', 'Home Team Shots','Away Team Shots', 'Home Team Shots on Target', 'Away Team Shots on Target', 'Home Fouls Committed', 'Away Fouls Committed', 'Home Corners', 'Away Corners', 'Home Yellow Cards', 'Away Yellow Cards', 'Home Red Cards', 'Away Red Cards']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We have to change the type of some variable (Date)\n",
    "data['Date'] = pd.to_datetime(data['Date'],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Tendencies through scatter plots\n",
    "\n",
    "A match has 3 different possible results (the Home Team wins, the Away Team wins or a Draw match). Each of these results are likely to happen, or not happen. This fact shows **the need of a binary variable**, for each of the match result (Home, Away or Draw)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We wo, one for the Home team wins, one for the draws and one for the Away team wins\n",
    "data = pd.get_dummies(data, columns=['Match Result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a betting strategy, it is first relevant to know how frequently the betting companies makes right predicting or not. So, in order to understand this fact, we will build **three different scatter plot**, showing the realised and not realised predictions :\n",
    "\n",
    "- When the official result is the victory of the home team crossed with the \"Home team win\" odd.\n",
    "- When the official result is the victory of the away team crossed with the \"Away team win\" odd.\n",
    "- When the official result is draw match crossed with the \"Draw\"odd.\n",
    "\n",
    "We will build scatter plots for each of the 3 differents possible results we have in a match, and compare them with the odds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home team wins scenario: if the Home team wins the output is 1,  otherwise it's 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of Homewin vs No Home win\n",
    "Homewin = data[\"Match Result_H\"].value_counts()[1]\n",
    "NoHomewin = data[\"Match Result_H\"].value_counts()[0]\n",
    "print(\"Home won:\", Homewin)\n",
    "print(\"Home did not win:\", NoHomewin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Base rate \n",
    "# the base rate of the No Home Win\n",
    "BaseRate = NoHomewin/data['Match Result_H'].count()\n",
    "BaseRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: We can see that we have a almost 50-50 repartition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "#tips = sns.load_dataset(data)\n",
    "\n",
    "a_B365_Home = sns.scatterplot(x=\"B365 Home\", y=\"Match Result_H\", data=data)\n",
    "\n",
    "a_BetWin_Home = sns.scatterplot(x=\"Bet&Win Home\", y=\"Match Result_H\", data=data)\n",
    "\n",
    "a_Interwetten_Home = sns.scatterplot(x=\"Interwetten Home\", y=\"Match Result_H\", data=data)\n",
    "\n",
    "a_WilliamHill_Home = sns.scatterplot(x=\"William Hill Home\", y=\"Match Result_H\", data=data)\n",
    "\n",
    "a_VCBet_Home = sns.scatterplot(x=\"VC Bet Home\", y=\"Match Result_H\", data=data)\n",
    "\n",
    "a_VCBet_Home.set(xlabel='Website Odd while Home Team wins', ylabel='Home team won [1]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** As we can see the higher the odd is, the less a team has chance to win. However, it still happen sometimes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw match scenario: if the result is draw, the output is 1,  otherwise it's 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of Draw vs No Draw\n",
    "Draw = data[\"Match Result_D\"].value_counts()[1]\n",
    "NoDraw = data[\"Match Result_D\"].value_counts()[0]\n",
    "print(\"Draw match:\", Draw)\n",
    "print(\"No Draw match:\", NoDraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Base rate \n",
    "# the base rate of the No Draw\n",
    "BaseRateD = NoDraw/data['Match Result_D'].count()\n",
    "BaseRateD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: We can see that we have a almost 75-25 repartition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_B365_Draw = sns.scatterplot(x=\"B365 Draw\", y=\"Match Result_D\", data=data)\n",
    "\n",
    "a_BetWin_Draw = sns.scatterplot(x=\"Bet&Win Draw\", y=\"Match Result_D\", data=data)\n",
    "\n",
    "a_Interwetten_Draw = sns.scatterplot(x=\"Interwetten Draw\", y=\"Match Result_D\", data=data)\n",
    "\n",
    "a_WilliamHill_Draw = sns.scatterplot(x=\"William Hill Draw\", y=\"Match Result_D\", data=data)\n",
    "\n",
    "a_VCBet_Draw = sns.scatterplot(x=\"VC Bet Draw\", y=\"Match Result_D\", data=data)\n",
    "\n",
    "a_VCBet_Draw.set(xlabel='Website Odd while Draw match', ylabel='Draw [1]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** We can observe the same trend as the previous graph for the small odds. However, the high odds just never realize themselves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Away team wins scenario: if the Away team wins the output is 1,  otherwise it's 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of Away win vs No Away win\n",
    "Awaywin = data[\"Match Result_A\"].value_counts()[1]\n",
    "NoAwaywin = data[\"Match Result_A\"].value_counts()[0]\n",
    "print(\"Away won:\", Awaywin)\n",
    "print(\"Away did not win:\", NoAwaywin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Base rate \n",
    "# the base rate of the No Home Win\n",
    "BaseRateA = NoAwaywin/data['Match Result_A'].count()\n",
    "BaseRateA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: We can see that we have a almost 70-30 repartition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_B365_Away = sns.scatterplot(x=\"B365 Away\", y=\"Match Result_A\", data=data)\n",
    "\n",
    "a_BetWin_Away = sns.scatterplot(x=\"Bet&Win Away\", y=\"Match Result_A\", data=data)\n",
    "\n",
    "a_Interwetten_Away = sns.scatterplot(x=\"Interwetten Away\", y=\"Match Result_A\", data=data)\n",
    "\n",
    "a_WilliamHill_Away = sns.scatterplot(x=\"William Hill Away\", y=\"Match Result_A\", data=data)\n",
    "\n",
    "a_VCBet_Away = sns.scatterplot(x=\"VC Bet Away\", y=\"Match Result_H\", data=data)\n",
    "\n",
    "a_VCBet_Away.set(xlabel='Website Odd while Away Team wins', ylabel='Away team won [1]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** We can observe the same trend as the previous graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison between two Classification models\n",
    "\n",
    "We will compare two model:\n",
    "\n",
    "> - **Logistic Regressions**: comparing the Odd prediction to the statistics of the match prediction\n",
    "> - **Decision Trees**: comparing the Odd prediction to the statistics of the match prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the models, we will normalise the odds numbers to create a common scale for all the odds.\n",
    "\n",
    "## On doit changer avec scalenorm truc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# separate the data from the target attributes\n",
    "#X = data['B365 Home','B365 Draw','B365 Away','Bet&Win Home','Bet&Win Draw','Bet&Win Away','Interwetten Home','Iterwetten Draw','Interwetten Away','William Hill Home','William Hill Draw','William Hill Away','VC Bet Home','VC Bet Draw','VC Bet Away']\n",
    "# normalisation par formule (x - x.min()) / (x.max() - x.min())\n",
    "cols_to_norm = ['B365 Home','B365 Draw','B365 Away','Bet&Win Home','Bet&Win Draw','Bet&Win Away','Interwetten Home','Interwetten Draw','Interwetten Away','William Hill Home','William Hill Draw','William Hill Away','VC Bet Home','VC Bet Draw','VC Bet Away']\n",
    "data[cols_to_norm] = data[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min())) \n",
    "data[cols_to_norm].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. With the odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is **the 1st logistic regression for Home Team Win:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['B365 Home','Bet&Win Home','Interwetten Home','William Hill Home','VC Bet Home']\n",
    "\n",
    "X = np.array(data[feature_names])\n",
    "y = np.array(data[\"Match Result_H\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression with 5 fold cross validation\n",
    "LR = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best regulariser parameter\n",
    "LR.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "LR.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train set accuracy is about 64%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set accuracy is about 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, LR.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see the repartition of results and predictions, but just below the confusion matrix shows it in a more readable way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confusion matrix, (code from the Lab 5.0)\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "y_pred = LR.predict(X_train)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Reds):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.ylim([-0.5, 2.5])\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout();\n",
    "    \n",
    "    ax.xaxis.set_ticklabels([\"No Home Win\", \"Home Win\"])\n",
    "    ax.yaxis.set_ticklabels([\"No Home Win\", \"Home Win\"])\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_train, y_pred, classes = y[unique_labels(y_train, y_pred)],title='Confusion matrix, with normalization')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLICATIONS CONFUSION MATRIX 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
    "\n",
    "Precision = precision_score(y_train, y_pred)\n",
    "\n",
    "print(Precision)\n",
    "# precision (60.42% of the games were a Home win )\n",
    "\n",
    "Recall = recall_score(y_train, y_pred)\n",
    "\n",
    "\n",
    "print(Recall)\n",
    "# recall (only 75.8% of the Home wins have been correctly identified)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLICATIONS RECALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Here is the 2nd logistic regression for Draws:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['B365 Draw','Bet&Win Draw','Interwetten Draw','William Hill Draw','VC Bet Draw']\n",
    "\n",
    "X = np.array(data[feature_names])\n",
    "y = np.array(data[\"Match Result_D\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression with 5 fold cross validation\n",
    "LRD = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRD.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best regulariser parameter\n",
    "LRD.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do not have asatisfying result : we should take sample of the data to have a better repartition of the [0,1] representing the results of the matches. \n",
    "### MORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "LRD.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "LRD.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRD.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expliquer que les resultats des cellules du dessus est due à cause de la mauvaise répartition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, LRD.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confusion matrix, (code from the Lab 5.0)\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "y_pred = LRD.predict(X_train)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Greens):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, with normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.ylim([-0.5, 2.5])\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout();\n",
    "    \n",
    "    ax.xaxis.set_ticklabels([\"No Draw\", \"Draw\"])\n",
    "    ax.yaxis.set_ticklabels([\"No Draw\", \"Draw\"])\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_train, y_pred, classes = y[unique_labels(y_train, y_pred)],title='Confusion matrix, with normalization')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mauvaise repartition alors on ne gardera pas l'example de draw pour les logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here is the 3rd logistic regression for Away wins:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['B365 Away','Bet&Win Away','Interwetten Away','William Hill Away','VC Bet Away']\n",
    "\n",
    "X = np.array(data[feature_names])\n",
    "y = np.array(data[\"Match Result_A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression with 5 fold cross validation\n",
    "LRA = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRA.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best regulariser parameter\n",
    "LRA.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "LRA.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "LRA.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, LRA.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confusion matrix, (code from the Lab 5.0)\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "y_pred = LRA.predict(X_train)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, with normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.ylim([-0.5, 2.5])\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout();\n",
    "    \n",
    "    ax.xaxis.set_ticklabels([\"No Away win\", \"Away win\"])\n",
    "    ax.yaxis.set_ticklabels([\"No Away win\", \"Away win\"])\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_train, y_pred, classes = y[unique_labels(y_train, y_pred)],title='Confusion matrix, with normalization')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mauvaise repartition alors on ne gardera pas l'example de away pour les logistic regression, meme raison que draw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### II. With the Match Statistics\n",
    "\n",
    "**Logistic Regression for Home win with statistics**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"Home ex-Rank\",\"Home Team Shots\",\"Away ex-Rank\", \"Away Team Shots\",\"Home Team Shots on Target\", \"Away Team Shots on Target\", \"Home Fouls Committed\", \"Away Fouls Committed\", \"Home Corners\", \"Away Corners\", \"Home Yellow Cards\", \"Away Yellow Cards\", \"Home Red Cards\", \"Away Red Cards\"]\n",
    "#feature_names = ['B365 Home']\n",
    "X = np.array(data[feature_names])\n",
    "y = np.array(data[\"Match Result_H\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression with 5 fold cross validation\n",
    "LR_MS = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_MS.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best regulariser parameter\n",
    "LR_MS.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "LR_MS.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "LR_MS.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, LR_MS.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confusion matrix, (code from the Lab 5.0)\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "y_pred = LR_MS.predict(X_train)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Reds):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, with normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.ylim([-0.5, 2.5])\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout();\n",
    "    \n",
    "    ax.xaxis.set_ticklabels([\"No Home win\", \"Home win\"])\n",
    "    ax.yaxis.set_ticklabels([\"No Home win\", \"Home win\"])\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_train, y_pred, classes = y[unique_labels(y_train, y_pred)],title='Confusion matrix, with normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression for Draws with statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"Home ex-Rank\",\"Home Team Shots\",\"Away ex-Rank\", \"Away Team Shots\",\"Home Team Shots on Target\", \"Away Team Shots on Target\", \"Home Fouls Committed\", \"Away Fouls Committed\", \"Home Corners\", \"Away Corners\", \"Home Yellow Cards\", \"Away Yellow Cards\"]\n",
    "#feature_names = ['B365 Home']\n",
    "X = np.array(data[feature_names])\n",
    "y = np.array(data[\"Match Result_D\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression with 5 fold cross validation\n",
    "LR_MSD = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_MSD.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best regulariser parameter\n",
    "LR_MSD.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "LR_MSD.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "LR_MSD.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, LR_MSD.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confusion matrix, (code from the Lab 5.0)\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "y_pred = LR_MSD.predict(X_train)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Greens):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, with normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.ylim([-0.5, 2.5])\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout();\n",
    "    \n",
    "    ax.xaxis.set_ticklabels([\"No Draw\", \"Draw\"])\n",
    "    ax.yaxis.set_ticklabels([\"No Draw\", \"Draw\"])\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_train, y_pred, classes = y[unique_labels(y_train, y_pred)],title='Confusion matrix, with normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression for Away win with statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"Home ex-Rank\",\"Home Team Shots\",\"Away ex-Rank\", \"Away Team Shots\",\"Home Team Shots on Target\", \"Away Team Shots on Target\", \"Home Fouls Committed\", \"Away Fouls Committed\", \"Home Corners\", \"Away Corners\", \"Home Yellow Cards\", \"Away Yellow Cards\", \"Home Red Cards\", \"Away Red Cards\"]\n",
    "#feature_names = ['B365 Home']\n",
    "X = np.array(data[feature_names])\n",
    "y = np.array(data[\"Match Result_A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# logistic regression with 5 fold cross validation\n",
    "LR_MSA = LogisticRegressionCV(solver='lbfgs', cv=5, max_iter=1000, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_MSA.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best regulariser parameter\n",
    "LR_MSA.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "LR_MSA.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "LR_MSA.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, LR_MSA.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized confusion matrix, (code from the Lab 5.0)\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "y_pred = LR_MSA.predict(X_train)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, with normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.ylim([-0.5, 2.5])\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout();\n",
    "    \n",
    "    ax.xaxis.set_ticklabels([\"No Away win\", \"Away win\"])\n",
    "    ax.yaxis.set_ticklabels([\"No Away win\", \"Away win\"])\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_train, y_pred, classes = y[unique_labels(y_train, y_pred)],title='Confusion matrix, with normalization')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Decision Trees\n",
    "\n",
    "#### I. With the Odds\n",
    "\n",
    "**Decision Tree for Home win**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['B365 Home','Bet&Win Home','Interwetten Home','William Hill Home','VC Bet Home']\n",
    "\n",
    "X = data[feature_names]\n",
    "y = data[\"Match Result_H\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth of the decision tree\n",
    "Depth = clf.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = DecisionTreeClassifier(criterion='entropy')\n",
    "scores = [clf.score(X_test,y_test)]\n",
    "for d in range(1, Depth):\n",
    "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=d)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores,\"r\")\n",
    "plt.ylabel('accuracy', fontsize=15)\n",
    "plt.xlabel('depth', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_Depth = np.argmax(scores)\n",
    "print(\"The optimal Maximum Depth is\", Max_Depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMax = DecisionTreeClassifier(criterion='entropy', max_depth=Max_Depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMax.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMax.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLICATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree for Draw**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_namesD = ['B365 Draw','Bet&Win Draw','Interwetten Draw','William Hill Draw','VC Bet Draw']\n",
    "\n",
    "X = data[feature_names]\n",
    "y = data[\"Match Result_D\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfD = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfD.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "clfD.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth of the decision tree\n",
    "Depth = clfD.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [clfD.score(X_test,y_test)]\n",
    "for d in range(1, Depth):\n",
    "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=d)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores,\"g\")\n",
    "plt.ylabel('accuracy', fontsize=15)\n",
    "plt.xlabel('depth', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_Depth = np.argmax(scores)\n",
    "print(\"The optimal Maximum Depth is\", Max_Depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMaxD = DecisionTreeClassifier(criterion='entropy', max_depth=Max_Depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMaxD.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMaxD.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLICATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree for Away win**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_namesA = ['B365 Away','Bet&Win Away','Interwetten Away','William Hill Away','VC Bet Away']\n",
    "\n",
    "X = data[feature_names]\n",
    "y = data[\"Match Result_A\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfA = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfA.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "clfA.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# depth of the decision tree\n",
    "Depth = clfA.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = [clfA.score(X_test,y_test)]\n",
    "for d in range(1, Depth):\n",
    "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=d)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)\n",
    "plt.ylabel('accuracy', fontsize=15)\n",
    "plt.xlabel('depth', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_Depth = np.argmax(scores)\n",
    "print(\"The optimal Maximum Depth is\", Max_Depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMaxA = DecisionTreeClassifier(criterion='entropy', max_depth=Max_Depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMaxA.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMaxA.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. With the Match Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Match Statistics for Home win**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Home ex-Rank', 'Home Team Shots', 'Away ex-Rank', 'Away Team Shots', 'Home Team Shots on Target', 'Away Team Shots on Target', 'Home Fouls Committed', 'Away Fouls Committed', 'Home Corners', 'Away Corners', 'Home Yellow Cards', 'Away Yellow Cards', 'Home Red Cards', 'Away Red Cards']\n",
    "\n",
    "X = np.array(data[feature_names])\n",
    "y = np.array(data[\"Match Result_H\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfHS = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfHS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "clfHS.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth of the decision tree\n",
    "clfHS.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [clfHS.score(X_test,y_test)]\n",
    "for d in range(1, Depth):\n",
    "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=d)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores, \"r\")\n",
    "plt.ylabel('accuracy', fontsize=15)\n",
    "plt.xlabel('depth', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_Depth = np.argmax(scores)\n",
    "print(\"The optimal Maximum Depth is\", Max_Depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMaxHS = DecisionTreeClassifier(criterion='entropy', max_depth=Max_Depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMaxHS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMaxHS.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Match Statistics for Draw**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Home ex-Rank', 'Home Team Shots', 'Away ex-Rank', 'Away Team Shots', 'Home Team Shots on Target', 'Away Team Shots on Target', 'Home Fouls Committed', 'Away Fouls Committed', 'Home Corners', 'Away Corners', 'Home Yellow Cards', 'Away Yellow Cards', 'Home Red Cards', 'Away Red Cards']\n",
    "\n",
    "X = np.array(data[feature_names])\n",
    "y = np.array(data[\"Match Result_D\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfDS = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfDS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "clfDS.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth of the decision tree\n",
    "clfDS.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [clfDS.score(X_test,y_test)]\n",
    "for d in range(1, Depth):\n",
    "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=d)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores,\"g\")\n",
    "plt.ylabel('accuracy', fontsize=15)\n",
    "plt.xlabel('depth', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_Depth = np.argmax(scores)\n",
    "print(\"The optimal Maximum Depth is\", Max_Depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMaxDS = DecisionTreeClassifier(criterion='entropy', max_depth=Max_Depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMaxDS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMaxDS.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Match Statistics for Away**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Home ex-Rank', 'Home Team Shots', 'Away ex-Rank', 'Away Team Shots', 'Home Team Shots on Target', 'Away Team Shots on Target', 'Home Fouls Committed', 'Away Fouls Committed', 'Home Corners', 'Away Corners', 'Home Yellow Cards', 'Away Yellow Cards', 'Home Red Cards', 'Away Red Cards']\n",
    "\n",
    "X = np.array(data[feature_names])\n",
    "y = np.array(data[\"Match Result_A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfAS = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfAS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "clfAS.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth of the decision tree\n",
    "clfAS.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [clfAS.score(X_test,y_test)]\n",
    "for d in range(1, Depth):\n",
    "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=d)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)\n",
    "plt.ylabel('accuracy', fontsize=15)\n",
    "plt.xlabel('depth', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_Depth = np.argmax(scores)\n",
    "print(\"The optimal Maximum Depth is\", Max_Depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMaxAS = DecisionTreeClassifier(criterion='entropy', max_depth=Max_Depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMaxAS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfMaxAS.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
